{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_gasoline = pd.read_csv(\"../tests/gasoline.csv\", index_col=0, parse_dates=True)\n",
    "df_gasoline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "df_gasoline['value'].plot()\n",
    "plt.title('Gasoline Prices in the US - Weekly')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Dollars per Gallon')\n",
    "plt.savefig('../results/gasoline.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality in the data\n",
    "\n",
    "We seek to examine the seasonality in the data. We will do this by looking at the autocorrelation function (ACF) and partial autocorrelation function (PACF) of the data. We will also look at the periodogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots:\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "plt.rc(\"figure\", figsize=(20,10))\n",
    "plot_acf(df_gasoline['value'], lags=20)\n",
    "plt.savefig('../results/gasoline_acf.png')\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(df_gasoline['value'], lags=20, method='ywm')\n",
    "plt.savefig('../results/gasoline_pacf.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "autocorrelation_plot(df_gasoline['value'])\n",
    "plt.savefig('../results/gasoline_autocorrelation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "data = df_gasoline['value']\n",
    "data = np.array(data)\n",
    "# scale the data\n",
    "data = (data - data.mean()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.arange(0, len(data) - test_size).reshape(-1, 1)\n",
    "y_train = data[:len(x_train)]\n",
    "x_test = np.arange(len(data) - test_size, len(data)).reshape(-1, 1)\n",
    "y_test = data[len(x_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear_reg = LinearRegression().fit(x_train, y_train)\n",
    "y_predicted = model_linear_reg.predict(x_test)\n",
    "\n",
    "# plot predictions\n",
    "x_train_plot = np.arange(0, len(x_train))\n",
    "x_test_plot = np.arange(len(x_train), len(x_train) + len(x_test))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_train_plot, y_train)\n",
    "plt.plot(x_test_plot, y_test)\n",
    "plt.plot(x_test_plot, y_predicted)\n",
    "plt.legend(['train', 'test', 'predicted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_test_plot, y_test)\n",
    "plt.plot(x_test_plot, y_predicted)\n",
    "plt.legend([ 'test', 'predicted'])\n",
    "plt.ylim(-0.2, 0.6)\n",
    "plt.savefig('../results/gasoline_linear_regression.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"RMSE: \", math.sqrt(mean_squared_error(y_test, y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Model - for capturing seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "\n",
    "data = df_gasoline['value'].values\n",
    "\n",
    "\n",
    "# fit model\n",
    "model = ARIMA(data, order=(5,1,0))\n",
    "model_fit = model.fit()\n",
    "# summary of fit model\n",
    "print(model_fit.summary())\n",
    "# line plot of residuals\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "# density plot of residuals\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "# summary stats of residuals\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "autocorrelation_plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a rolling forecast ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model using a walk-forward validation\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "# load dataset\n",
    "\n",
    "series = df_gasoline['value']\n",
    "# split into train and test sets\n",
    "X = series.values\n",
    "# normalize dataset\n",
    "X = X.astype('float32')\n",
    "X = (X - X.mean()) / (X.max() - X.min())\n",
    "\n",
    "size = len(X) - test_size\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "# walk-forward validation\n",
    "for t in tqdm(range(len(test))):\n",
    "\tmodel = ARIMA(history, order=(5,1,0))\n",
    "\tmodel_fit = model.fit()\n",
    "\toutput = model_fit.forecast()\n",
    "\tyhat = output[0]\n",
    "\tpredictions.append(yhat)\n",
    "\tobs = test[t]\n",
    "\thistory.append(obs)\n",
    "\n",
    "model_fit.plot_diagnostics(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate forecasts\n",
    "rmse = math.sqrt(mean_squared_error(test, predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# plot forecasts against actual outcomes\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.ylim(-0.2, 0.6)\n",
    "plt.legend(['test', 'predicted'])\n",
    "plt.savefig('../results/gasoline_arima.png')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.contrib.examples.bart import load_bart_od\n",
    "from pyro.contrib.forecast import ForecastingModel, Forecaster, backtest, eval_crps\n",
    "from pyro.infer.reparam import LocScaleReparam, StableReparam\n",
    "from pyro.ops.tensor_utils import periodic_cumsum, periodic_repeat, periodic_features\n",
    "from pyro.ops.stats import quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(ForecastingModel):\n",
    "    # We then implement the .model() method. Since this is a generative model, it shouldn't\n",
    "    # look at data; however it is convenient to see the shape of data we're supposed to\n",
    "    # generate, so this inputs a zeros_like(data) tensor instead of the actual data.\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)  # Should be 1 in this univariate tutorial.\n",
    "        feature_dim = covariates.size(-1)\n",
    "\n",
    "        # The first part of the model is a probabilistic program to create a prediction.\n",
    "        # We use the zero_data as a template for the shape of the prediction.\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "        prediction = bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        # The prediction should have the same shape as zero_data (duration, obs_dim),\n",
    "        # but may have additional sample dimensions on the left.\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # The next part of the model creates a likelihood or noise distribution.\n",
    "        # Again we'll be Bayesian and write this as a probabilistic program with\n",
    "        # priors over parameters.\n",
    "        noise_scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Normal(0, noise_scale)\n",
    "\n",
    "        # The final step is to call the .predict() method.\n",
    "        self.predict(noise_dist, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(data, dtype=torch.float)\n",
    "# scale data to be between -1 and 1\n",
    "data = (data - data.mean()) / (data.max() - data.min())\n",
    "\n",
    "# add observation dimension\n",
    "data.unsqueeze_(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 0\n",
    "end = data.size(-2)\n",
    "mid = end - test_size\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(end)) / 52\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = torch.stack([time], dim=-1)\n",
    "print(covariates.shape, data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = Forecaster(Model1(), data[:mid], covariates[:mid], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:mid], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[mid:])\n",
    "print(samples.shape, p10.shape)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(mid, end), data[mid:], 'k-', label='truth')\n",
    "plt.xlim(mid, None)\n",
    "plt.ylim(-0.2, 0.6)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('../results/gasoline_pyro_m1.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"RMSE: \", math.sqrt(mean_squared_error(data[mid:], p50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(end)) / 365\n",
    "covariates = torch.cat([time.unsqueeze(-1),\n",
    "                        periodic_features(end, 52)], dim=-1)\n",
    "forecaster = Forecaster(Model1(), data[:mid], covariates[:mid], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:mid], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[mid:])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(mid, end), data[mid:], 'k-', label='truth')\n",
    "plt.xlim(mid, None)\n",
    "plt.ylim(-0.2, 0.6)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('../results/gasoline_pyro_m1_seasonal.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"RMSE: \", math.sqrt(mean_squared_error(data[mid:], p50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "\n",
    "        # We'll sample a time-global scale parameter outside the time plate,\n",
    "        # then time-local iid noise inside the time plate.\n",
    "        drift_scale = pyro.sample(\"drift_scale\",\n",
    "                                  dist.LogNormal(-20, 5).expand([1]).to_event(1))\n",
    "        with self.time_plate:\n",
    "            # We'll use a reparameterizer to improve variational fit. The model would still be\n",
    "            # correct if you removed this context manager, but the fit appears to be worse.\n",
    "            with poutine.reparam(config={\"drift\": LocScaleReparam()}):\n",
    "                drift = pyro.sample(\"drift\", dist.Normal(zero_data, drift_scale).to_event(1))\n",
    "\n",
    "        # After we sample the iid \"drift\" noise we can combine it in any time-dependent way.\n",
    "        # It is important to keep everything inside the plate independent and apply dependent\n",
    "        # transforms outside the plate.\n",
    "        motion = drift.cumsum(-2)  # A Brownian motion.\n",
    "\n",
    "        # The prediction now includes three terms.\n",
    "        prediction = motion + bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # Construct the noise distribution and predict.\n",
    "        noise_scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Normal(0, noise_scale)\n",
    "        self.predict(noise_dist, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(end)) / 365\n",
    "# covariates = torch.stack([time], dim=-1)\n",
    "covariates = torch.cat([time.unsqueeze(-1),\n",
    "                        periodic_features(end, 52)], dim=-1)\n",
    "forecaster = Forecaster(Model2(), data[:mid], covariates[:mid], learning_rate=0.1, time_reparam=\"dct\", num_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:mid], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[mid:])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(mid, end), data[mid:], 'k-', label='truth')\n",
    "plt.xlim(mid, None)\n",
    "plt.ylim(-0.2, 0.6)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('../results/gasoline_pyro_m2.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"RMSE: \", math.sqrt(mean_squared_error(data[mid:], p50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "\n",
    "        drift_scale = pyro.sample(\"drift_scale\", dist.LogNormal(-20, 5).expand([1]).to_event(1))\n",
    "        with self.time_plate:\n",
    "            with poutine.reparam(config={\"drift\": LocScaleReparam()}):\n",
    "                drift = pyro.sample(\"drift\", dist.Normal(zero_data, drift_scale).to_event(1))\n",
    "        motion = drift.cumsum(-2)  # A Brownian motion.\n",
    "\n",
    "        prediction = motion + bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # The next part of the model creates a likelihood or noise distribution.\n",
    "        # Again we'll be Bayesian and write this as a probabilistic program with\n",
    "        # priors over parameters.\n",
    "        stability = pyro.sample(\"noise_stability\", dist.Uniform(1, 2).expand([1]).to_event(1))\n",
    "        skew = pyro.sample(\"noise_skew\", dist.Uniform(-1, 1).expand([1]).to_event(1))\n",
    "        scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Stable(stability, skew, scale)\n",
    "\n",
    "        # We need to use a reparameterizer to handle the Stable distribution.\n",
    "        # Note \"residual\" is the name of Pyro's internal sample site in self.predict().\n",
    "        with poutine.reparam(config={\"residual\": StableReparam()}):\n",
    "            self.predict(noise_dist, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(2)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(end)) / 365\n",
    "covariates = periodic_features(end, 52)\n",
    "forecaster = Forecaster(Model3(), data[:mid], covariates[:mid], learning_rate=0.1,\n",
    "                        time_reparam=\"dct\")\n",
    "for name, value in forecaster.guide.median().items():\n",
    "    if value.numel() == 1:\n",
    "        print(\"{} = {:0.4g}\".format(name, value.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:mid], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[mid:])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('../results/gasoline_pyro_m3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.fill_between(torch.arange(mid, end), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(mid, end), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(mid, end), data[mid:], 'k-', label='truth')\n",
    "plt.xlim(mid, None)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('../results/gasoline_pyro_m3.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"RMSE: \", math.sqrt(mean_squared_error(data[mid:], p50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting using pyro - evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "windows1 = backtest(data, covariates, Model1,\n",
    "                    min_train_window=62, test_window=100, stride=50,\n",
    "                    forecaster_options={\"learning_rate\": 0.1, \"time_reparam\": \"dct\",\n",
    "                                        \"log_every\": 1000, \"warm_start\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "windows2 = backtest(data, covariates, Model2,\n",
    "                    min_train_window=62, test_window=100, stride=50,\n",
    "                    forecaster_options={\"learning_rate\": 0.1, \"time_reparam\": \"dct\",\n",
    "                                        \"log_every\": 1000, \"warm_start\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "windows3 = backtest(data, covariates, Model3,\n",
    "                    min_train_window=62, test_window=100, stride=50,\n",
    "                    forecaster_options={\"learning_rate\": 0.1, \"time_reparam\": \"dct\",\n",
    "                                        \"log_every\": 1000, \"warm_start\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, figsize=(20, 20), sharex=True)\n",
    "\n",
    "axes[0].plot([w[\"crps\"] for w in windows2], \"bx\", label=\"local gaussian\")\n",
    "axes[0].plot([w[\"crps\"] for w in windows1], \"ro\", label=\"global gaussian\")\n",
    "axes[0].plot([w[\"crps\"] for w in windows3], \"g+\", label=\"heavy-tailed Stable\")\n",
    "# draw line joining the points\n",
    "axes[0].plot([w[\"crps\"] for w in windows2], \"b\", alpha=0.3)\n",
    "axes[0].plot([w[\"crps\"] for w in windows1], \"r\", alpha=0.3)\n",
    "axes[0].plot([w[\"crps\"] for w in windows3], \"g\", alpha=0.3)\n",
    "axes[0].set_ylabel(\"CRPS\")\n",
    "\n",
    "axes[1].plot([w[\"mae\"] for w in windows2], \"bx\", label=\"local gaussian\")\n",
    "axes[1].plot([w[\"mae\"] for w in windows1], \"ro\", label=\"global gaussian\")\n",
    "axes[1].plot([w[\"mae\"] for w in windows3], \"g+\", label=\"heavy-tailed Stable\")\n",
    "# draw line joining the points\n",
    "axes[1].plot([w[\"mae\"] for w in windows2], \"b\", alpha=0.3)\n",
    "axes[1].plot([w[\"mae\"] for w in windows1], \"r\", alpha=0.3)\n",
    "axes[1].plot([w[\"mae\"] for w in windows3], \"g\", alpha=0.3)\n",
    "axes[1].set_ylabel(\"MAE\")\n",
    "\n",
    "axes[2].plot([w[\"rmse\"] for w in windows2], \"bx\", label=\"local gaussian\")\n",
    "axes[2].plot([w[\"rmse\"] for w in windows1], \"ro\", label=\"global gaussian\")\n",
    "axes[2].plot([w[\"rmse\"] for w in windows3], \"g+\", label=\"heavy-tailed Stable\")\n",
    "# draw line joining the points\n",
    "axes[2].plot([w[\"rmse\"] for w in windows2], \"b\", alpha=0.3)\n",
    "axes[2].plot([w[\"rmse\"] for w in windows1], \"r\", alpha=0.3)\n",
    "axes[2].plot([w[\"rmse\"] for w in windows3], \"g\", alpha=0.3)\n",
    "axes[2].set_ylabel(\"RMSE\")\n",
    "\n",
    "axes[0].legend(loc=\"best\")\n",
    "plt.savefig('../results/gasoline_pyro_comparison.png')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
